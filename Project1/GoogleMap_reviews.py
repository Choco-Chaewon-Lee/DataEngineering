import sys 
import time
import json
import pandas as pd
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from webdriver_manager.chrome import ChromeDriverManager

# ì €ì¥ ê²½ë¡œ
from pymongo import MongoClient
client = MongoClient("")
db = client["dataEngineering"]
collection = db["GoogleMap_jeju"]


# Chrome WebDriver ì„¤ì •
options = Options()
options.add_argument("--start-maximized")
options.add_argument("--disable-blink-features=AutomationControlled")
service = Service(ChromeDriverManager().install())
driver = webdriver.Chrome(service=service, options=options)

# Google Maps ì œì£¼ë„ ì—¬í–‰ì§€ ê²€ìƒ‰
url = "https://www.google.co.kr/maps/search/ì œì£¼ë„+ì—¬í–‰ì§€/data=!3m1!4b1!4m2!2m1!6e1?hl=ko"
driver.get(url)
time.sleep(5)

# ê²€ìƒ‰ ê²°ê³¼ ë¡œë”© ëŒ€ê¸° ë° ìŠ¤í¬ë¡¤
scrollable_div = WebDriverWait(driver, 10).until(
    EC.presence_of_element_located((By.XPATH, '//div[contains(@aria-label, "ê²€ìƒ‰ê²°ê³¼") and @role="feed"]'))
)
for _ in range(25):
    driver.execute_script("arguments[0].scrollTop = arguments[0].scrollHeight", scrollable_div)
    time.sleep(2)

# ì¥ì†Œ ë§í¬ ìˆ˜ì§‘
place_cards = driver.find_elements(By.CSS_SELECTOR, 'div.Nv2PK')
place_links = []
for card in place_cards:
    try:
        link = card.find_element(By.TAG_NAME, "a").get_attribute("href")
        if "/place/" in link:
            place_links.append(link)
    except:
        continue
print(f"\nğŸ‘‰ ì´ ìˆ˜ì§‘ëœ ì¥ì†Œ ë§í¬ ê°œìˆ˜: {len(place_links)}ê°œ")

if len(place_links) < 120:
    print("âŒ ìˆ˜ì§‘ëœ ì¥ì†Œ ë§í¬ 120ê°œ ë¯¸ë§Œ --> í”„ë¡œê·¸ë¨ ì¢…ë£Œ")
    sys.exit()

# ê²°ê³¼ ì €ì¥ ë¦¬ìŠ¤íŠ¸
results = []
idx, valid_place_count = 0, 0
review_total = 0

while valid_place_count < 120 and idx < len(place_links):
    place_url = place_links[idx]
    idx += 1
    try:
        driver.get(place_url)
        WebDriverWait(driver, 10).until(
            EC.presence_of_element_located((By.CSS_SELECTOR, 'h1.DUwDvf.lfPIob'))
        )
        time.sleep(2)

        # ì¥ì†Œ ì´ë¦„
        try:
            name = driver.find_element(By.CSS_SELECTOR, 'h1.DUwDvf.lfPIob').text.strip()
        except:
            name = ""


        # ë¦¬ë·° íƒ­ í´ë¦­
        try:
            review_tab = WebDriverWait(driver, 10).until(
                EC.presence_of_element_located((By.XPATH, '//button[contains(@aria-label, "ë¦¬ë·°")]'))
            )
            driver.execute_script("arguments[0].scrollIntoView(true);", review_tab)
            time.sleep(1)
            driver.execute_script("arguments[0].click();", review_tab)
            time.sleep(3)
        except:
            continue

        # ë¦¬ë·° ìŠ¤í¬ë¡¤
        try:
            review_container = WebDriverWait(driver, 5).until(
                EC.presence_of_element_located((By.CSS_SELECTOR, 'div.m6QErb.DxyBCb.kA9KIf.dS8AEf'))
            )
            last_height = 0
            for _ in range(100): # ë¦¬ë·° ìˆ˜ ì¡°ì • key point
                driver.execute_script("arguments[0].scrollTop = arguments[0].scrollHeight", review_container)
                time.sleep(1.5)
                new_height = driver.execute_script("return arguments[0].scrollHeight", review_container)
                if new_height == last_height:
                    break
                last_height = new_height
        except:
            continue

        # ë¦¬ë·° ìˆ˜ì§‘
        reviews_data = []
        review_elements = driver.find_elements(By.CLASS_NAME, 'jJc9Ad')
        for element in review_elements:
            try:
                # ì „ì²´ ë¦¬ë·° ë³´ê¸° í´ë¦­
                try:
                    more_btn = element.find_element(By.CLASS_NAME, 'w8nwRe')
                    driver.execute_script("arguments[0].click();", more_btn)
                except:
                    pass

                review_text = element.find_element(By.XPATH, './/span[@class="wiI7pd"]').text.strip()
                star_elements = element.find_elements(By.XPATH, './/span[@class="hCCjke google-symbols NhBTye elGi1d"]')
                review_rating = len(star_elements) if star_elements else "No rating"
                reviewer_name = element.find_element(By.XPATH, './/div[contains(@class, "d4r55 ")]').text.strip()
                reviews_data.append({
                    "reviewer": reviewer_name,
                    "rating": review_rating,
                    "content": review_text
                })
                review_total += 1
            except:
                continue

        results.append({
            "tour_name": name,
            "reviews": reviews_data
        })

        valid_place_count += 1
        print(f"{idx+1}. {name} - ë¦¬ë·° {len(reviews_data)}ê°œ ìˆ˜ì§‘ ì™„ë£Œ")

    except:
        continue


# ë¦¬ë·° ì €ì¥
for place in results:
    tour_name = place["tour_name"]
    reviews = place["reviews"]

    if not tour_name or not reviews:
        continue

    existing_doc = collection.find_one({"tour_name": tour_name})

    if existing_doc:
        # ê¸°ì¡´ ë¬¸ì„œì— ë¦¬ë·° ì¶”ê°€
        collection.update_one(
            {"tour_name": tour_name},
            {"$push": {"reviews": {"$each": reviews}}}
        )
        print(f"âœ… '{tour_name}'ì— ë¦¬ë·° {len(reviews)}ê°œ ì¶”ê°€ ì™„ë£Œ.")
    else:
        # ë¬¸ì„œê°€ ì—†ìœ¼ë©´ ìƒˆë¡œ ìƒì„±
        new_doc = {
            "tour_name": tour_name, 
            "avg_rating": None,
            "address": None,
            "latitude": None,
            "longitude": None,
            "review_count": None,
            "reviews": reviews
        }
        collection.insert_one(new_doc)
        print(f"ğŸ†• '{tour_name}' ìƒˆ ë¬¸ì„œ ìƒì„± ë° ë¦¬ë·° {len(reviews)}ê°œ ì¶”ê°€ ì™„ë£Œ.")